:imagesdir: ../assets/images

[#model-deployment]
= Introduction to your environment

Our first step is to get accustomed to our environment and its components. 

Our home base will be our OpenShift cluster web console:

// NOTE: If you are accessing these instructions through our Red Hat Demo Platform workshop, the information below will render properly with unique values. If you are accessing the instructions separately for your own cluster, from the GitHub repository, you will instead see placeholder values.

URL: https://console-openshift-console.{openshift_cluster_ingress_domain}/[https://console-openshift-console.{openshift_cluster_ingress_domain}/,window=_blank].
* Login to OpenShift ({user}/{password}) 

From here, we will navigate to and between the following environments throughout our workshop:

* Cluster Argo CD
** View our gitops application deployments. This may be useful if you need to check the health of any of our apps.
* Grafana
** A dashboard interface that will show us model usage metrics.
* Red Hat OpenShift AI
** Where we will view and manage our model deployments and other MLOps/LLMOps tasks and agentic resources.
* Red Hat OpenShift Dev Spaces
** Where we will go into our developer persona and leverage our model as a service setup for coding tasks.

You may find and go to these locations via our navigation button in the web console:

image::apps-menu.png[]

Now that you know how to get around, your adventure begins!

== View model deployment

OpenShift AI provides a web-based dashboard interface to deploy and manage models with ease, at scale and in conjunction with other critical AI assets like MCP servers or evaluation tooling.

Let's get connected.

**Open the OpenShift AI Dashboard**

Click the navigation button and select **Red Hat OpenShift AI** from the drop-down menu.

image::nav-rhoai.png[]

If prompted, login again with your user credentials to the OpenShift AI dashboard.

Once authenticated you will see the following home page:

image::rhoai-dashboard.png[]

Now, go to the `Gen AI Studio` section of the dashboard and select `AI asset endpoints`.

image::nav-genaistudio.png[]

In the AI asset endpoints page, change the project from `grafana` to `Workspace userx` with x equal to your assigned user number.

image::genaistudio-changeproject.png[]

Now you may view your available asset endpoints.

You will not see any available models under the `Models` tab. Why? Because you do not have a model deployed in this namespace. 

We do, however, have a model deployed in a separate namespace managed by our cluster admin. This admin has set up a `Models as a Service` architecture for our organization, with a central model deployed and managed, available for use by disparate teams. 

We will not be able to manage the model deployment with our simple user privileges, but we can access its endpoint information for use via the `Models as a service` tab. 

image::maas-tab.png[]

Select the tab. You will see we have one model deployed: `qwen-4b-instruct`

image::maas-model.png[]

// Test model in playground

We need the endpoint for the next section. Select `View` under the `External endpoint` column:

image::view-endpoint.png[]

Copy the MaaS route into a separate note file on your computer.

image::copy-route.png[]

Now, click `Generate API token`.

image::generate-token.png[]

Copy this value alongside your route endpoint.

image::copy-token.png[]

Now that we have our model connection details, we can proceed to our development environment to leverage the model. 
